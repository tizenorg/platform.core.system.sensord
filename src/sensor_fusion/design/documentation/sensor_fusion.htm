<html>
<head><title>Sensor Fusion for Tizen Sensor Framework</title></head>

<h1><center>Sensor Fusion for Tizen Sensor Framework</center></h1>

<h2>Introduction</h2>

<p>Sensor Fusion is the process of combining the accelerometer,
gyroscope and geo-magnetic sensor in order to generate accurate virtual sensor
outputs such as Orientation, Gravity, Linear Acceleration, etc. Sensor Fusion 
is used for extracting individual virtual sensor components from composite
sensor data and/or combining multiple sensor data to create new sensor component
data while compensating for individual sensor errors. Ideally the following
errors would have to be corrected during sensor fusion:-</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Bias: Any non-zero sensor
output when the input is zero</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Scale factor error: error
resulting from aging or manufacturing tolerances</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Nonlinearity: Present in
most sensors to some degree</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Scale factor sign asymmetry:
Often mismatched push-pull amplifiers</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Dead zone: usually due to
mechanical lock-in</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- Quantization error: inherent
in all digitized systems</p>

<h2>Sensors Used for Sensor Fusion</h2>

<p>Accelerometer Sensor :- Accelerometer data is a combination of linear
acceleration and gravity components. Applications would be interested in using
linear acceleration and gravity sensor data separately. Sensor fusion could be
used to separate linear acceleration and gravity components.  Additionally,
accelerometer is used for correcting the roll and pitch orientation measurements
generated from the gyroscope. Using the same, corrected tilt measurement (roll
and pitch) is generated. </p>

<p>Gyroscope Sensor :- It is ideal to determine the orientation of the device,
but has the problem of long term drift in the measured sensor values. Sensor
Fusion could be used to combine Accelerometer, Gyroscope and Geomagnetic (Compass)
sensor data to produce corrected orientation data without drift.</p>

<p>Geo-Magnetic Sensor :- Provides the direction the device is pointed in relation
to the earth's magnetic field. Could be used along with gyroscope angular rotation
along Z axis to produce correct yaw measurement. Geo-Magnetic sensor along with
GPS latitude-longitude measurements could be used to accurately estimate
heading of the device.</p>

<h2>Orientation Estimation</h2>

<p><center></center></p>

<FIGURE>
<center>
<img src="./diagram/device_orientation.png" width="30%" height="40%">
<FIGCAPTION>Fig. 1. Device Orientation in Euler Angles.</FIGCAPTION>
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./diagram/block_diagram_orientation_estimation.png" width="40%"
height="80%">
<FIGCAPTION>Fig. 2. Quaternion based Sensor Fusion Approach for Orientation
Estimation.</FIGCAPTION>
</center>
</FIGURE>

<h3>Preprocessing of Sensor Data</h3>

<FIGURE>
<center>
<img src="./equation/equation_1.png" width="35%" height="5%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_2.png" width="35%" height="6%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_3.png" width="35%" height="10%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_4.png" width="35%" height="10%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_5.png" width="35%" height="10%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_6.png" width="35%" height="5%">
</center>
</FIGURE>


<h3>Orientation Computation Based on Aiding System</h3>

<FIGURE>
<center>
<img src="./equation/equation_7.png" width="35%" height="4%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_8.png" width="35%" height="4%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_9.png" width="35%" height="4%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_10.png" width="35%" height="4%">
</center>
</FIGURE>

<FIGURE>
<center>
<img src="./equation/equation_11.png" width="35%" height="4%">
</center>
</FIGURE>


<h3>Driving System</h3>


<p>The accelerometer and geomagnetic sensor data are corrected
for noise and compensated for static bias. Accelerometer is used to compute
tilt (pitch and roll). The geomagnetic sensor along with the computed tilt data
is used compute yaw. The computed Euler angles (pitch, roll and yaw) are
converted to quaternions.</p>

<h3>Noise Covariance Computation</h3>

<p>The process noise covariance (Q) is calculated by computing
covariance of windowed block of driving system data. The measurement noise
covariance (R) is calculated by computing covariance of windowed block of aiding
system data. The process and measurement covariance computed are to be used in
Kalman filtering.</p>

<h3>Kalman Filtering</h3>

<FIGURE>
<center>
<img src="./diagram/kalman_filter_stages.png">
<FIGCAPTION>Fig. 3. Kalman Filter Stages.</FIGCAPTION>
</center>
</FIGURE>

<p>To ensure linear Kalman filtering the following error state equation is used:</p>

<p><img src="./equation/state_equation.png"></p>

<p>,where the first term is the quaternion representation of the Euler angles
error and the next three terms are the error in knowledge of bias errors.</p>

<h3>Determination of Gravity</h3>
<p>When a device is subjected to motion in Euclidean space, the 3D accelerometer
data generated from the device is a combination of linear acceleration and gravity
components which are a measure of linear and rotational motion respectively.The
gravity measurements in 3D space are derived from the orientation (pitch, roll
and yaw) measurements that is output from the Kalman filter. The process to compute
gravity and linear acceleration is shown in figure below.

<FIGURE>
<center>
<img src="./diagram/block_diagram_gravity_and_linear_acceleration.png"
width="40%" height="40%">
<FIGCAPTION>Fig. 4. Computation of Gravity and Linear Acceleration.</FIGCAPTION>
</center>
</FIGURE>

<p>Gravity virtual sensor data provides the measure of the direction in which the
Earth’s gravitational force is observed in the device’s frame of reference. The
orientation of the device decides the measure of the influence of Earth’s gravitational
force on the 3-axes of the device. The following equations are used for projecting
the tilt(pitch, roll) of the device on the Earth’s gravity axis to determine earth’s
gravitational effect on the devices reference axis.</p>

<p>GRx = Earth’s Gravity * sin(pitch)</p>
<p>GRy = Earth’s Gravity * sin(roll)</p>
<p>GRz = Earth’s Gravity * cos(pitch) * cos(roll)</p>

<FIGURE>
<center>
<img src="./diagram/orientation_effect_on_gravity.png">
<FIGCAPTION>Fig. 5. Effect of Device Orientation on Gravity.</FIGCAPTION>
</center>
</FIGURE>

<p>When the device tilt values (pitch,roll) are changed from (0,0) to (0,&Pi;/2),
phone is rotated around x-axis, the y-axis gets aligned to earth's gravitational field
after rotation instead of the z-axis.  When this rotation is applied to the equations
given above, the values (GRx,GRy,GRz) are converted from (0,0,G) to (0,G,0) due to the
shift in the axis which experiences the gravitational field (G is measure of Earth's
gravity).</p>

<h2>Determination of Linear Acceleration</h2>

<p>Linear Acceleration virtual sensor data provides the measure of the acceleration of
a device after removing the Gravity components on the 3-axes. Accurate linear
acceleration data are calculated by subtracting gravity components from the 3-axes
calibrated accelerometer data.</p>

<p>LAx = Ax – GRy</p>
<p>LAy = Ay – GRx</p>
<p>LAz = Az – GRz</p>

<h1>References</h1>

<p>[1] Gebre-Egziabher, H., Rhayward, R. C. &amp; Powell, J. D. Design
of Multi-Sensor Attitude Determination Systems. IEEE Transactions on
Aerospace and Electronic Systems, (Volume: 40, Issue: 2), 627 - 649 (2004)</p>

<p>[2] Abyarjoo1, F., Barreto1, A., Cofino1, J. &amp; Ortega, F. R., Implementing
a Sensor Fusion Algorithm for 3D Orientation Detection with Inertial/Magnetic
Sensors. The International Joint Conferences on CISSE (2012)</p>

<p>[3] Marcard, T. V., Design and Implementation of an attitude estimation system to
control orthopedic components. Chalmers University. Master thesis published on
the university link http://publications.lib.chalmers.se/records/fulltext/125985.pdf(2010)</p>

<p>[4] Welch, G., Bishop, G. An introduction to the Kalman Filter: SIGGRAPH (2001)</p>

<p>[5] Grewal, M. S., Weill, L. R., Andrews, A. P., Global Positioning Systems,
Inertial Navigation, and Integration (John Wiley &amp; Sons., 2001)</p>

</html>
